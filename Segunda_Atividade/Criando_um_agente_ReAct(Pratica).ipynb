{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Instalando o GROQ**"
      ],
      "metadata": {
        "id": "O_In26_zgpq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C51DNLLqgneQ",
        "outputId": "34c03e91-cfd3-4ef8-d3d8-6fef1c464e31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definição de uma variavel de ambiente da chave API**\n",
        "\n",
        "No caso com o nome 'GROQ_API_KEY', junto com a chave que foi adiquirida.\n",
        "\n"
      ],
      "metadata": {
        "id": "JHPU1NOvhPul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LyfEK7mnSBNM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inicialização do cliente GROQ e teste da chave API**"
      ],
      "metadata": {
        "id": "CQpA8GMPiDwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "#Iniciamos o groq e aplicamos a chave api\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "#Uma mensagem simples para testar se tudo está certo até agora\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL2HEnpwiYVY",
        "outputId": "d4101df3-c56a-4189-8165-7965fd7f1979"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are crucial in today's technology landscape, and their importance can be understood from several perspectives:\n",
            "\n",
            "1. **Efficient Processing**: Fast language models can process and analyze large amounts of text data quickly, which is essential for applications that require real-time or near-real-time processing, such as chatbots, virtual assistants, and sentiment analysis tools.\n",
            "2. **Improved User Experience**: Fast language models enable applications to respond rapidly to user input, providing a more seamless and interactive experience. This is particularly important for applications that require immediate feedback, such as language translation, text summarization, and question-answering systems.\n",
            "3. **Scalability**: Fast language models can handle a large volume of requests and data, making them ideal for large-scale applications, such as social media platforms, search engines, and content management systems.\n",
            "4. **Reduced Latency**: Fast language models minimize latency, which is critical for applications that require fast response times, such as real-time language translation, speech recognition, and text-to-speech synthesis.\n",
            "5. **Energy Efficiency**: Fast language models can be more energy-efficient, as they require less computational power and memory to process text data. This is important for mobile devices, edge computing, and other applications where energy consumption is a concern.\n",
            "6. **Cost Savings**: Fast language models can reduce the computational resources required for text processing, leading to cost savings for organizations that rely on language models for their operations.\n",
            "7. **Enhanced Accuracy**: Fast language models can be trained on larger datasets and can learn from more examples, which can lead to improved accuracy and better performance on various natural language processing (NLP) tasks.\n",
            "8. **Real-time Insights**: Fast language models can provide real-time insights and analytics, enabling organizations to respond quickly to changing market conditions, customer needs, and other factors that impact their business.\n",
            "\n",
            "Some of the key applications that benefit from fast language models include:\n",
            "\n",
            "1. **Virtual assistants**: Fast language models enable virtual assistants, such as Siri, Alexa, and Google Assistant, to respond quickly to user queries and provide accurate results.\n",
            "2. **Language translation**: Fast language models facilitate real-time language translation, enabling users to communicate across languages and cultures.\n",
            "3. **Sentiment analysis**: Fast language models can analyze large amounts of text data to provide real-time insights into customer sentiment and opinions.\n",
            "4. **Chatbots**: Fast language models power chatbots, enabling them to respond quickly and accurately to user queries and provide personalized support.\n",
            "5. **Text summarization**: Fast language models can summarize long documents and articles, providing users with concise and relevant information.\n",
            "\n",
            "In summary, fast language models are essential for a wide range of applications that require efficient, accurate, and real-time text processing. Their importance extends to various industries, including technology, healthcare, finance, and customer service, where they can improve user experience, reduce latency, and provide valuable insights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criação do Agente em si**"
      ],
      "metadata": {
        "id": "9piWLGkLkLRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent: #Criação da clase agente\n",
        "\n",
        "  def __init__ (self,client,system): #definição de uma função que irá iniciar meu agente\n",
        "    self.client = client #Inicializamos primeiro o cliente\n",
        "    self.system = system #Logo em seguida iremos inicializar o \"System Prompt\"\n",
        "    self.messages = [] #Criação de uma lista de um loop de mensagens que o agente irá incluir em sua memória\n",
        "    if self.system is not None: #Caso exista uma mensagem do sistema nos acidionaremos à nossa lista de mensagens\n",
        "      self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
        "\n",
        "  def __call__ (self, message = \"\"): #Uma chamada que será executada sem que o Agent for executado\n",
        "    if message: #Se o usuária enviar uma mensagem ela será adicionada na lista\n",
        "      self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "    result = self.execute() #Agora executaremos o modulo de linguagem, ou seja o Agent\n",
        "    self.messages.append({\"role\": \"assistant\", \"content\": result}) #Adicionaremos o resultado do \"def execute\" à lista\n",
        "    return result\n",
        "\n",
        "  def execute(self): #Irá rodar todas as mensagens do usuária, junto ao modelo desejado\n",
        "    completion = client.chat.completions.create(\n",
        "        messages= self.messages,\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "KJ4DKR4_kOYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crição do Prompt do sistema e das ferramente que ele terá a disposição**"
      ],
      "metadata": {
        "id": "AsN4naXcoBSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O meu desejo para criar uma pratica com o agente que foi ensinado em video era que ele pudesse acessar informações de peso e altura de certas pessoas e com isso calcular o BMI (BMI é a expressão em inglês de IMC que significa Índice de Massa Corporal) esse era meu objetivo, porém após terminar eu achei que seria interessante se o agente também pudesse dizer qual o estado corporal do indivíuo escolhido, se ele está abaixo do peso, acima, obseidade e etc, assim eu criei esse prompt para que isso fosse possível."
      ],
      "metadata": {
        "id": "DwCHFSBjuoVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt do sistema\n",
        "system_prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "get_weight_data:\n",
        "e.g. get_weight_data: Pedro\n",
        "returns weight of the person in kilograms\n",
        "\n",
        "get_height_data:\n",
        "e.g. get_height_data: Pedro\n",
        "returns height of the person in meters\n",
        "\n",
        "calcule_IMC\n",
        "e.g. calcule_BMI: 86.32/1.80**2\n",
        "returns the BMI of a person\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: What is Pedro's BMI?\n",
        "\n",
        "Thought: I need to find Pedro's weight first.\n",
        "Action: get_weight_data: Pedro\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "\n",
        "Observation: 86.2\n",
        "\n",
        "Thought: Now I need to find Pedro's height.\n",
        "Action: get_height_data: Pedro\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "\n",
        "Observation: 1.80\n",
        "\n",
        "Thought: Now I have both weight and height. I will now calculate the BMI using the correct formula and expect the result as my next observation.\n",
        "Action: calculate_IMC: 86.2 / (1.80 ** 2)\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: 26.60\n",
        "\n",
        "Thought: Now I have Pedro's. I will cheky what is his body condition,\n",
        "Action: classify_BMI: 26.60\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: Overweight\n",
        "\n",
        "If you have the answer, output it as the Answer.\n",
        "\n",
        "Answer: Pedro's BMI is 26.60 and he is Overweight.\n",
        "\n",
        "Now it's your turn:\n",
        "\"\"\".strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "EYYw6jrIoGJZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TOOLS**"
      ],
      "metadata": {
        "id": "bov-ZJitjm-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui estão as tools relacionadas ao meu agente 'Nutricionista'"
      ],
      "metadata": {
        "id": "psnnPnRZvZWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ferramentas\n",
        "#tranfomaremos em um função, as ferramentas que foram mencionadas no prompt (calcular, e pegar a massa dos planetas) , para que assim o Agent possa ter acesso a ela\n",
        "\n",
        "def calculate(operation) -> float:\n",
        "  return eval(operation)\n",
        "\n",
        "def calculate_BMI(operation) -> float:\n",
        "  return eval(operation)\n",
        "\n",
        "def get_weight_data(name: str) -> float:\n",
        "    match name.lower():\n",
        "        case \"pedro\":\n",
        "            return 86.2\n",
        "        case \"caio\":\n",
        "            return 55.7\n",
        "        case \"vitor\":\n",
        "            return 85.0\n",
        "        case \"ana\":\n",
        "            return 62.5\n",
        "        case \"maria\":\n",
        "            return 72.0\n",
        "        case \"joao\":\n",
        "            return 79.0\n",
        "        case \"lucas\":\n",
        "            return 68.0\n",
        "        case \"carla\":\n",
        "            return 58.1\n",
        "        case \"patricia\":\n",
        "            return 70.0\n",
        "        case \"gabriel\":\n",
        "            return 77.5\n",
        "        case \"luciana\":\n",
        "            return 64.5\n",
        "        case \"rafael\":\n",
        "            return 82.5\n",
        "        case \"gabriela\":\n",
        "            return 60.5\n",
        "        case \"beatriz\":\n",
        "            return 65.0\n",
        "        case _:\n",
        "            return 0.0\n",
        "\n",
        "def get_height_data(name: str) -> float:\n",
        "    match name.lower():\n",
        "        case \"pedro\":\n",
        "            return 1.80\n",
        "        case \"caio\":\n",
        "            return 1.75\n",
        "        case \"vitor\":\n",
        "            return 1.85\n",
        "        case \"ana\":\n",
        "            return 1.65\n",
        "        case \"maria\":\n",
        "            return 1.70\n",
        "        case \"joao\":\n",
        "            return 1.78\n",
        "        case \"lucas\":\n",
        "            return 1.72\n",
        "        case \"carla\":\n",
        "            return 1.60\n",
        "        case \"patricia\":\n",
        "            return 1.68\n",
        "        case \"gabriel\":\n",
        "            return 1.80\n",
        "        case \"luciana\":\n",
        "            return 1.63\n",
        "        case \"rafael\":\n",
        "            return 1.82\n",
        "        case \"gabriela\":\n",
        "            return 1.67\n",
        "        case \"beatriz\":\n",
        "            return 1.72\n",
        "        case _:\n",
        "            return 0.0\n",
        "\n",
        "def classify_BMI(BMI: float) -> str:\n",
        "    # Garantir que BMI seja um número do tipo float\n",
        "    BMI = float(BMI)\n",
        "\n",
        "    match BMI:\n",
        "        case BMI if BMI < 18.5:\n",
        "            return \"Underweight\"\n",
        "        case BMI if 18.5 <= BMI < 25:\n",
        "            return \"Normal Weight\"\n",
        "        case BMI if 25 <= BMI < 30:\n",
        "            return \"Overweight\"\n",
        "        case BMI if 30 <= BMI < 35:\n",
        "            return \"Obesity Grade 1\"\n",
        "        case BMI if 35 <= BMI < 40:\n",
        "            return \"Obesity Grade 2\"\n",
        "        case _:\n",
        "            return \"Obesity Grade 3\"\n"
      ],
      "metadata": {
        "id": "nhjPo41BYqp1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crição de um loop para o Agent**\n",
        "\n",
        "Isso irá acabar com a necessidade de uma pessoa ficar chamando o agente toda vez que desejarmos que ele pense (assim como feito anteriormente), através de um loop ele será capaz de fazer isso por conta própria"
      ],
      "metadata": {
        "id": "JXhtMmCsvr1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # Importação da biblioteca \"Regular Expressions\", pois precisaremos analisar os conteúdos de uma string\n",
        "\n",
        "def agent_loop(max_iterations=10, query: str = \"\"):\n",
        "    # Inicialização do agente\n",
        "    agent = Agent(client, system_prompt)\n",
        "    tools = ['calculate', 'calculate_BMI', 'get_weight_data', 'get_height_data', 'classify_BMI'] # Inicializando o nome das ferramentas que temos\n",
        "    next_prompt = query\n",
        "    i = 0\n",
        "\n",
        "    while i < max_iterations: # Início do loop\n",
        "        i += 1\n",
        "        result = agent(next_prompt) # Chamamos o Agent e verificamos o resultado\n",
        "        print(result)\n",
        "\n",
        "        if \"PAUSE\" in result and \"Action\" in result: # Se o resultado tiver uma ação e pausa\n",
        "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
        "\n",
        "            if action:\n",
        "                chosen_tool = action[0][0]\n",
        "                arg = action[0][1]\n",
        "\n",
        "                if chosen_tool in tools:\n",
        "                    result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
        "                    next_prompt = f\"Observation: {result_tool}\"\n",
        "\n",
        "                else:\n",
        "                    next_prompt = \"Observation: Tool not found\"\n",
        "            else:\n",
        "                next_prompt = \"Observation: No valid action found\"\n",
        "\n",
        "            print(next_prompt)\n",
        "            continue\n",
        "\n",
        "        if \"Answer\" in result: # A resposta foi encontrada e podemos sair do loop\n",
        "            break\n"
      ],
      "metadata": {
        "id": "shAcVhjkqXad"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testes**\n",
        "Meu principal intuito, como mencionado anteriormente era encontrar o BMI da uma pessoa e descobrir qual era o estado corporal da quela pessoa, sobrepeso, obeso ou etc, assim eu fiz o teste e ocorreu tudo certo."
      ],
      "metadata": {
        "id": "zc34IVJptUpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(query=\"what is Vitor's BMI and body condition?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NracxNPn1s1J",
        "outputId": "c551a4d8-43b2-44c3-cc14-2ce20693875b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find Vitor's weight first to calculate his BMI.\n",
            "Action: get_weight_data: Vitor\n",
            "PAUSE\n",
            "Observation: 85.0\n",
            "Thought: Now I need to find Vitor's height to calculate his BMI using the correct formula.\n",
            "Action: get_height_data: Vitor\n",
            "PAUSE\n",
            "Observation: 1.85\n",
            "Thought: Now I have both weight and height. I will now calculate the BMI using the correct formula and expect the result as my next observation.\n",
            "Action: calcule_IMC: 85.0 / (1.85 ** 2)\n",
            "PAUSE\n",
            "Observation: Tool not found\n",
            "Thought: It seems the tool \"calcule_IMC\" is not available. However, I can use the \"calculate\" tool to calculate the BMI. The formula for BMI is weight / height^2.\n",
            "Action: calculate: 85.0 / (1.85 ** 2)\n",
            "PAUSE\n",
            "Observation: 24.835646457268076\n",
            "Thought: Now I have Vitor's BMI. I will now classify his BMI to determine his body condition.\n",
            "Action: classify_BMI: 24.835646457268076\n",
            "PAUSE\n",
            "Observation: Normal Weight\n",
            "Thought: Now I have Vitor's BMI and his body condition. I can now provide the answer.\n",
            "Action: None\n",
            "Answer: Vitor's BMI is 24.84 and he is Normal Weight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse segundo texte eu queria testar além, minha intenção era ver se o agent realmente poderia responder outras perguntas apenas com as ferramentas que eu lhe dei, e não apenas à pergunta a qual ele foi intruido a pensar, agir e observar, teste esse que deu certo."
      ],
      "metadata": {
        "id": "BwleDmnhtpPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(query=\"Between Pedro and Vitor who has the highest BMI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FikhSq3amxQy",
        "outputId": "2bd3962c-37e7-431f-ac50-fcc8d1bdce03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: To determine who has the highest BMI between Pedro and Vitor, I need to calculate the BMI of both individuals. First, I need to find Pedro's weight and height, then Vitor's weight and height, and finally calculate their respective BMIs.\n",
            "\n",
            "Action: get_weight_data: Pedro\n",
            "PAUSE\n",
            "Observation: 86.2\n",
            "Thought: Now that I have Pedro's weight, I need to find his height to calculate his BMI.\n",
            "\n",
            "Action: get_height_data: Pedro\n",
            "PAUSE\n",
            "Observation: 1.8\n",
            "Thought: Now that I have Pedro's weight and height, I can calculate his BMI. However, to compare it with Vitor's, I also need Vitor's weight and height. Let's calculate Pedro's BMI first.\n",
            "\n",
            "Action: calculate: 86.2 / (1.8 ** 2)\n",
            "PAUSE\n",
            "Observation: 26.604938271604937\n",
            "Thought: Now that I have Pedro's BMI, I need to find Vitor's weight to calculate his BMI for comparison.\n",
            "\n",
            "Action: get_weight_data: Vitor\n",
            "PAUSE\n",
            "Observation: 85.0\n",
            "Thought: Now that I have Vitor's weight, I need to find his height to calculate his BMI.\n",
            "\n",
            "Action: get_height_data: Vitor\n",
            "PAUSE\n",
            "Observation: 1.85\n",
            "Thought: Now that I have Vitor's weight and height, I can calculate his BMI and compare it with Pedro's.\n",
            "\n",
            "Action: calculate: 85.0 / (1.85 ** 2)\n",
            "PAUSE\n",
            "Observation: 24.835646457268076\n",
            "Thought: Now that I have both Pedro's and Vitor's BMIs, I can compare them to determine who has the highest BMI. Pedro's BMI is approximately 26.60, and Vitor's BMI is approximately 24.84.\n",
            "\n",
            "Action: calculate: 26.60 > 24.84\n",
            "PAUSE\n",
            "Observation: True\n",
            "Thought: Since the result of the comparison is True, it means Pedro's BMI is higher than Vitor's. Therefore, I can conclude that Pedro has the highest BMI between the two.\n",
            "\n",
            "Answer: Pedro has the highest BMI.\n"
          ]
        }
      ]
    }
  ]
}